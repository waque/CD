{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import time, warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle, islice\n",
    "from sklearn import cluster, datasets, mixture\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./aps_failure_training_set.csv',\n",
    "                        skiprows=20,keep_default_na=False, na_values='na')\n",
    "test = pd.read_csv('./aps_failure_test_set.csv',\n",
    "                        skiprows=20,keep_default_na=False, na_values='na')\n",
    "\n",
    "aps = pd.concat([train, test])\n",
    "aps = aps.drop(columns=['class'])\n",
    "aps = aps.fillna(aps.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(aps)\n",
    "aps = scaler.transform(aps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up cluster parameters\n",
    "plt.figure(figsize=(9 * 2 + 3, 12.5))\n",
    "plt.subplots_adjust(left=.02,right=.98,bottom=.001,top=.96,wspace=.05,hspace=.01)\n",
    "default_base = {'quantile': .3,'eps': .3, 'damping': .9, 'preference': -200, 'n_neighbors': 10, 'n_clusters': 3}\n",
    "datasets = [\n",
    "(aps,{'damping':.77,'preference':-240,'quantile':.2,'n_clusters':2}),\n",
    "(aps, {'damping': .75, 'preference': -220, 'n_clusters': 2}),\n",
    "(aps, {'eps': .18, 'n_neighbors': 3}),\n",
    "(aps, {'eps': .15, 'n_neighbors': 2}),\n",
    "(aps, {}),\n",
    "(aps, {})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_dataset, (dataset, algo_params) in enumerate(datasets):\n",
    "    # update parameters with dataset-specific values\n",
    "    params = default_base.copy()\n",
    "    params.update(algo_params)\n",
    "    X = dataset\n",
    "    \n",
    "    # estimate bandwidth for mean shift\n",
    "    bandwidth = cluster.estimate_bandwidth(X, quantile=params['quantile'])\n",
    "    # connectivity matrix for structured Ward\n",
    "    connectivity = kneighbors_graph(X, n_neighbors=params['n_neighbors'], include_self=False)\n",
    "    # make connectivity symmetric\n",
    "    connectivity = 0.5 * (connectivity + connectivity.T)\n",
    "    # Create cluster objects\n",
    "    two_means = cluster.MiniBatchKMeans(n_clusters=params['n_clusters'])\n",
    "    ward = cluster.AgglomerativeClustering( n_clusters=params['n_clusters'], linkage='ward',\n",
    "    connectivity=connectivity)\n",
    "    spectral = cluster.SpectralClustering( n_clusters=params['n_clusters'], eigen_solver='arpack', affinity=\"nearest_neighbors\")\n",
    "    dbscan = cluster.DBSCAN(eps=params['eps'])\n",
    "    affinity_propagation = cluster.AffinityPropagation(damping=params['damping'], preference=params['preference'])\n",
    "    average_linkage = cluster.AgglomerativeClustering( linkage=\"average\", affinity=\"cityblock\", n_clusters=params['n_clusters'], connectivity=connectivity)\n",
    "    birch = cluster.Birch(n_clusters=params['n_clusters'])\n",
    "    gmm = mixture.GaussianMixture( n_components=params['n_clusters'], covariance_type='full')\n",
    "    clustering_algorithms = (('MiniBatchKMeans', two_means),('AffinityPropagation', affinity_propagation),('MeanShift', ms),('SpectralClustering', spectral),('Ward', ward),('AgglomerativeClustering', average_linkage),('DBSCAN', dbscan),('Birch', birch),('GaussianMixture', gmm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = {}\n",
    "for name, algorithm in clustering_algorithms:\n",
    "    t0 = time.time()\n",
    "    # catch warnings related to kneighbors_graph\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\",message=\"the number of connected components of the \" +\"connectivity matrix is [0-9]{1,2}\" +\" > 1. Completing it to avoid stopping the tree early.\",category=UserWarning)\n",
    "        warnings.filterwarnings(\"ignore\",message=\"Graph is not fully connected, spectral embedding\" +\" may not work as expected.\",category=UserWarning)\n",
    "        algorithm.fit(X)\n",
    "        t1 = time.time()\n",
    "    if hasattr(algorithm, 'labels_'):\n",
    "        y_pred = algorithm.labels_.astype(np.int)\n",
    "    else:\n",
    "        y_pred = algorithm.predict(X)\n",
    "    y_preds[name] = y_pred\n",
    "    plt.subplot(len(datasets), len(clustering_algorithms), plot_num)\n",
    "    if i_dataset == 0:\n",
    "        plt.title(name, size=18)\n",
    "    colors = np.array(list(islice(cycle(['#377eb8', '#ff7f00', '#4daf4a','#f781bf', '#a65628', '#984ea3','#999999', '#e41a1c', '#dede00']),int(max(y_pred) + 1))))\n",
    "    # add black color for outliers (if any)\n",
    "    colors = np.append(colors, [\"#000000\"])\n",
    "    plt.scatter(X[:, 0], X[:, 1], s=10, color=colors[y_pred])\n",
    "    plt.xlim(-2.5, 2.5)\n",
    "    plt.ylim(-2.5, 2.5)\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plot_num += 1\n",
    "    plt.savefig('cluster/{}.pdf'.format(name))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
