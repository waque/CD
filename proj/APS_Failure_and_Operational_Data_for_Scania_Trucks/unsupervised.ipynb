{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from utils_cd import (\n",
    "        split_dataset,\n",
    "        standard_deviation,\n",
    "        plot_comparison_results,\n",
    "        impute_values,\n",
    "        plot_results,\n",
    "        plot_param_improv,\n",
    "        plot_results_from_csv\n",
    ")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import Normalizer, StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "base_clfs = [BernoulliNB(), DecisionTreeClassifier(), KNeighborsClassifier(), RandomForestClassifier(n_estimators=100)]\n",
    "#base_clfs = [RandomForestClassifier(n_estimators=100)]\n",
    "\n",
    "CLASS = 'class'\n",
    "train = pd.read_csv('./aps_failure_training_set.csv',\n",
    "                        skiprows=20,keep_default_na=False, na_values='na')\n",
    "test = pd.read_csv('./aps_failure_test_set.csv',\n",
    "                        skiprows=20,keep_default_na=False, na_values='na')\n",
    "\n",
    "train['class'] = train['class'].map({'pos': 1, 'neg': 0})\n",
    "test['class'] = test['class'].map({'pos': 1, 'neg': 0})\n",
    "\n",
    "aps_class = pd.concat([train, test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded_columns = ['bv_000', 'bu_000', 'cq_000', 'ah_000', 'bt_000', 'cf_000', 'ad_000', 'cd_000']\n",
    "aps_class = aps_class.drop(columns=excluded_columns)\n",
    "aps = aps_class.drop(columns=['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We removed the columns based on the same criteria that on supervised\n",
    "We will now  test many support levels for finding association rules and we will test with discretization to see how the values vary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to discretize values rounding, first preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aps_class = aps_class.fillna(0).round().astype(int)\n",
    "aps = aps.round().fillna(0).astype(int)\n",
    "est = KBinsDiscretizer(n_bins=3, encode='onehot-dense', strategy='uniform')\n",
    "est.fit(aps)\n",
    "aps_3 = est.transform(aps)\n",
    "aps_3 = pd.DataFrame(data=aps_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-992c94597012>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfrequent_itemsets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapriori\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maps_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_support\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/mlxtend/frequent_patterns/apriori.py\u001b[0m in \u001b[0;36mapriori\u001b[0;34m(df, min_support, use_colnames, max_len, n_jobs)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \"\"\"\n\u001b[1;32m    105\u001b[0m     \u001b[0mallowed_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0munique_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munique_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallowed_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "frequent_itemsets = apriori(aps, min_support=0.3, use_colnames=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
