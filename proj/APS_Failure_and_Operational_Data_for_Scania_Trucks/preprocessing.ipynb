{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train missing values percentage: 99.015\n",
      "Test missing values percentage: 98.96875\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from utils_cd import (\n",
    "        split_dataset,\n",
    "        standard_deviation,\n",
    "        plot_comparison_results,\n",
    "        impute_values,\n",
    "        plot_results,\n",
    "        plot_param_improv\n",
    ")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import Normalizer, StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "base_clfs = [BernoulliNB(), DecisionTreeClassifier(), KNeighborsClassifier(), RandomForestClassifier(n_estimators=100)]\n",
    "#base_clfs = [RandomForestClassifier(n_estimators=100)]\n",
    "\n",
    "def print_missing_percentage(df, name='Dataset'):\n",
    "    print('{} missing values percentage: {}'.format(name, (df.shape[0] - df.dropna().shape[0]) / df.shape[0] * 100))\n",
    "\n",
    "CLASS = 'class'\n",
    "train = pd.read_csv('./aps_failure_training_set.csv',\n",
    "                        skiprows=20,keep_default_na=False, na_values='na')\n",
    "test = pd.read_csv('./aps_failure_test_set.csv',\n",
    "                        skiprows=20,keep_default_na=False, na_values='na')\n",
    "\n",
    "print_missing_percentage(train, 'Train')\n",
    "print_missing_percentage(test, 'Test')\n",
    "\n",
    "X_train, y_train = split_dataset(train, CLASS)\n",
    "X_test, y_test = split_dataset(test, CLASS)\n",
    "y_train = y_train.map({'pos': 1, 'neg': 0})\n",
    "y_test = y_test.map({'pos': 1, 'neg': 0})\n",
    "\n",
    "aps = pd.concat([X_train, X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   level_0 level_1    0\n",
      "0   bb_000  bv_000  1.0\n",
      "1   ah_000  bg_000  1.0\n",
      "2   aa_000  bt_000  1.0\n",
      "3   bv_000  cq_000  1.0\n",
      "4   bb_000  cq_000  1.0\n",
      "5   bu_000  cq_000  1.0\n",
      "6   bu_000  bv_000  1.0\n",
      "7   bb_000  bu_000  1.0\n",
      "8   cf_000  co_000  1.0\n",
      "9   ad_000  cf_000  1.0\n",
      "10  ad_000  co_000  1.0\n"
     ]
    }
   ],
   "source": [
    "def attribute_corr(df, top):\n",
    "        \n",
    "    def get_redundant_pairs(df):\n",
    "        '''Get diagonal and lower triangular pairs of correlation matrix'''\n",
    "        pairs_to_drop = set()\n",
    "        cols = df.columns\n",
    "        for i in range(0, df.shape[1]):\n",
    "            for j in range(0, i+1):\n",
    "                pairs_to_drop.add((cols[i], cols[j]))\n",
    "        return pairs_to_drop\n",
    "\n",
    "    def get_top_abs_correlations(df, n=5):\n",
    "        au_corr = df.corr().abs().unstack()\n",
    "        labels_to_drop = get_redundant_pairs(df)\n",
    "        au_corr = au_corr.drop(labels=labels_to_drop).sort_values(ascending=False)\n",
    "        return au_corr[0:n]\n",
    "\n",
    "    \n",
    "    return get_top_abs_correlations(df, top)\n",
    "\n",
    "correlated_features = attribute_corr(aps, 11)\n",
    "correlated_features = correlated_features.reset_index()\n",
    "print(correlated_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute sets {0: {'bb_000', 'cq_000', 'bu_000', 'bv_000'}, 1: {'ah_000', 'bg_000'}, 2: {'aa_000', 'bt_000'}, 3: {'cf_000', 'co_000', 'ad_000'}}\n",
      "Best attributes to select ['bb_000', 'bg_000', 'aa_000', 'cf_000']\n",
      "Excluded columns ['cq_000', 'bu_000', 'bv_000', 'ah_000', 'bt_000', 'co_000', 'ad_000']\n"
     ]
    }
   ],
   "source": [
    "equal_attrs = {}\n",
    "all_attrs = set([])\n",
    "sets = 0\n",
    "for index, corr in correlated_features.iterrows():\n",
    "    attr1 = corr['level_0']\n",
    "    attr2 = corr['level_1']\n",
    "    \n",
    "    present = False\n",
    "    if attr1 in equal_attrs:\n",
    "        equal_attrs[attr1].append(attr1)\n",
    "    for attr in equal_attrs:\n",
    "        if attr1 in equal_attrs[attr] or attr2 in equal_attrs[attr]:\n",
    "            equal_attrs[attr].add(attr1)\n",
    "            equal_attrs[attr].add(attr2)\n",
    "            present = True\n",
    "            \n",
    "    if not present:\n",
    "        equal_attrs[sets] = set([attr1, attr2])\n",
    "        sets += 1\n",
    "        \n",
    "best_attrs = []\n",
    "all_attrs = []\n",
    "for attrs in equal_attrs:\n",
    "    best_attr = None\n",
    "    best_nmr_missing = 600000\n",
    "    for attr in equal_attrs[attrs]:\n",
    "        all_attrs.append(attr)\n",
    "        nmr_missing = aps[attr].isna().sum()\n",
    "        if nmr_missing < best_nmr_missing:\n",
    "            best_attr = attr\n",
    "            best_nmr_missing = nmr_missing\n",
    "        \n",
    "    best_attrs.append(best_attr)\n",
    "\n",
    "excluded_columns = [item for item in all_attrs if item not in best_attrs]\n",
    "print('Attribute sets {}'.format(equal_attrs))\n",
    "print('Best attributes to select {}'.format(best_attrs))\n",
    "print('Excluded columns {}'.format(excluded_columns))\n",
    "\n",
    "aps = aps.drop(aps[excluded_columns], axis=1)\n",
    "X_train = X_train.drop(X_train[excluded_columns], axis=1)\n",
    "X_test = X_test.drop(X_test[excluded_columns], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes with 0 standard deviation ['cd_000']\n"
     ]
    }
   ],
   "source": [
    "no_std_dev = []\n",
    "for col in aps:\n",
    "    std_dev = standard_deviation(aps[col])\n",
    "    if std_dev == 0:\n",
    "        no_std_dev.append(col)\n",
    "        \n",
    "print('Attributes with 0 standard deviation {}'.format(no_std_dev))\n",
    "aps = aps.drop(aps[no_std_dev], axis=1)\n",
    "X_train = X_train.drop(X_train[no_std_dev], axis=1)\n",
    "X_test = X_test.drop(X_test[no_std_dev], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_zero, X_test_zero = X_train.fillna(0), X_test.fillna(0)\n",
    "X_train_mean, X_test_mean = X_train.fillna(X_train.mean()), X_test.fillna(X_train.mean())\n",
    "X_train_median, X_test_median = X_train.fillna(X_train.median()), X_test.fillna(X_train.median())\n",
    "X_train_mfrequent, X_test_mfrequent = X_train, X_test\n",
    "for col in X_train:\n",
    "    mode = X_train[col].dropna().mode()[0]\n",
    "    X_train_mfrequent[col] = X_train_mfrequent[col].fillna(mode) \n",
    "    X_test_mfrequent[col] = X_test_mfrequent[col].fillna(mode) \n",
    "\n",
    "X_data = {'Zero replace': (X_train_zero, X_test_zero), 'Mean': (X_train_mean, X_test_mean), 'Median': (X_train_median, X_test_median), 'Most Frequent': (X_train_mfrequent, X_test_mfrequent)}\n",
    "plot_comparison_results(base_clfs, X_data, y_train, y_test, technique='Technique', filename='missing_values', figsize=(20, 6))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
