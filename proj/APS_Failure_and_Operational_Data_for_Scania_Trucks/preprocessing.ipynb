{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train missing values percentage: 99.015\n",
      "Test missing values percentage: 98.96875\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from utils_cd import (\n",
    "        split_dataset,\n",
    "        standard_deviation,\n",
    "        plot_comparison_results,\n",
    "        impute_values,\n",
    "        plot_results,\n",
    "        plot_param_improv,\n",
    "        plot_results_from_csv\n",
    ")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import Normalizer, StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "base_clfs = [BernoulliNB(), DecisionTreeClassifier(), KNeighborsClassifier(), RandomForestClassifier(n_estimators=100)]\n",
    "#base_clfs = [RandomForestClassifier(n_estimators=100)]\n",
    "\n",
    "def print_missing_percentage(df, name='Dataset'):\n",
    "    print('{} missing values percentage: {}'.format(name, (df.shape[0] - df.dropna().shape[0]) / df.shape[0] * 100))\n",
    "\n",
    "CLASS = 'class'\n",
    "train = pd.read_csv('./aps_failure_training_set.csv',\n",
    "                        skiprows=20,keep_default_na=False, na_values='na')\n",
    "test = pd.read_csv('./aps_failure_test_set.csv',\n",
    "                        skiprows=20,keep_default_na=False, na_values='na')\n",
    "\n",
    "print_missing_percentage(train, 'Train')\n",
    "print_missing_percentage(test, 'Test')\n",
    "\n",
    "X_train, y_train = split_dataset(train, CLASS)\n",
    "X_test, y_test = split_dataset(test, CLASS)\n",
    "y_train = y_train.map({'pos': 1, 'neg': 0})\n",
    "y_test = y_test.map({'pos': 1, 'neg': 0})\n",
    "\n",
    "aps = pd.concat([X_train, X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   level_0 level_1    0\n",
      "0   bb_000  bv_000  1.0\n",
      "1   ah_000  bg_000  1.0\n",
      "2   bv_000  cq_000  1.0\n",
      "3   bb_000  cq_000  1.0\n",
      "4   aa_000  bt_000  1.0\n",
      "5   bu_000  cq_000  1.0\n",
      "6   bu_000  bv_000  1.0\n",
      "7   bb_000  bu_000  1.0\n",
      "8   cf_000  co_000  1.0\n",
      "9   ad_000  cf_000  1.0\n",
      "10  ad_000  co_000  1.0\n"
     ]
    }
   ],
   "source": [
    "def attribute_corr(df, top):\n",
    "        \n",
    "    def get_redundant_pairs(df):\n",
    "        '''Get diagonal and lower triangular pairs of correlation matrix'''\n",
    "        pairs_to_drop = set()\n",
    "        cols = df.columns\n",
    "        for i in range(0, df.shape[1]):\n",
    "            for j in range(0, i+1):\n",
    "                pairs_to_drop.add((cols[i], cols[j]))\n",
    "        return pairs_to_drop\n",
    "\n",
    "    def get_top_abs_correlations(df, n=5):\n",
    "        au_corr = df.corr().abs().unstack()\n",
    "        labels_to_drop = get_redundant_pairs(df)\n",
    "        au_corr = au_corr.drop(labels=labels_to_drop).sort_values(ascending=False)\n",
    "        return au_corr[0:n]\n",
    "\n",
    "    \n",
    "    return get_top_abs_correlations(df, top)\n",
    "\n",
    "correlated_features = attribute_corr(X_train, 11)\n",
    "correlated_features = correlated_features.reset_index()\n",
    "print(correlated_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute sets {0: {'bu_000', 'bv_000', 'cq_000', 'bb_000'}, 1: {'ah_000', 'bg_000'}, 2: {'aa_000', 'bt_000'}, 3: {'cf_000', 'ad_000', 'co_000'}}\n",
      "Best attributes to select ['bb_000', 'bg_000', 'aa_000', 'cf_000']\n",
      "Excluded columns ['bu_000', 'bv_000', 'cq_000', 'ah_000', 'bt_000', 'ad_000', 'co_000']\n"
     ]
    }
   ],
   "source": [
    "equal_attrs = {}\n",
    "all_attrs = set([])\n",
    "sets = 0\n",
    "for index, corr in correlated_features.iterrows():\n",
    "    attr1 = corr['level_0']\n",
    "    attr2 = corr['level_1']\n",
    "    \n",
    "    present = False\n",
    "    if attr1 in equal_attrs:\n",
    "        equal_attrs[attr1].append(attr1)\n",
    "    for attr in equal_attrs:\n",
    "        if attr1 in equal_attrs[attr] or attr2 in equal_attrs[attr]:\n",
    "            equal_attrs[attr].add(attr1)\n",
    "            equal_attrs[attr].add(attr2)\n",
    "            present = True\n",
    "            \n",
    "    if not present:\n",
    "        equal_attrs[sets] = set([attr1, attr2])\n",
    "        sets += 1\n",
    "        \n",
    "best_attrs = []\n",
    "all_attrs = []\n",
    "for attrs in equal_attrs:\n",
    "    best_attr = None\n",
    "    best_nmr_missing = 600000\n",
    "    for attr in equal_attrs[attrs]:\n",
    "        all_attrs.append(attr)\n",
    "        nmr_missing = aps[attr].isna().sum()\n",
    "        if nmr_missing < best_nmr_missing:\n",
    "            best_attr = attr\n",
    "            best_nmr_missing = nmr_missing\n",
    "        \n",
    "    best_attrs.append(best_attr)\n",
    "\n",
    "excluded_columns = [item for item in all_attrs if item not in best_attrs]\n",
    "print('Attribute sets {}'.format(equal_attrs))\n",
    "print('Best attributes to select {}'.format(best_attrs))\n",
    "print('Excluded columns {}'.format(excluded_columns))\n",
    "\n",
    "aps = aps.drop(aps[excluded_columns], axis=1)\n",
    "X_train = X_train.drop(X_train[excluded_columns], axis=1)\n",
    "X_test = X_test.drop(X_test[excluded_columns], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes with 0 standard deviation ['cd_000']\n"
     ]
    }
   ],
   "source": [
    "no_std_dev = []\n",
    "for col in aps:\n",
    "    std_dev = standard_deviation(aps[col])\n",
    "    if std_dev == 0:\n",
    "        no_std_dev.append(col)\n",
    "        \n",
    "print('Attributes with 0 standard deviation {}'.format(no_std_dev))\n",
    "aps = aps.drop(aps[no_std_dev], axis=1)\n",
    "X_train = X_train.drop(X_train[no_std_dev], axis=1)\n",
    "X_test = X_test.drop(X_test[no_std_dev], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Zero replace': {'BernoulliNB': {'predicted': array([0, 0, 0, ..., 0, 0, 0]),\n",
       "   'accuracy': 0.9049375,\n",
       "   'confusion_matrix': array([[14131,  1494],\n",
       "          [   27,   348]]),\n",
       "   'sensibility': 0.928,\n",
       "   'specificity': 0.904384,\n",
       "   'score': 28440},\n",
       "  'DecisionTreeClassifier': {'predicted': array([0, 0, 0, ..., 0, 0, 0]),\n",
       "   'accuracy': 0.988375,\n",
       "   'confusion_matrix': array([[15550,    75],\n",
       "          [  111,   264]]),\n",
       "   'sensibility': 0.704,\n",
       "   'specificity': 0.9952,\n",
       "   'score': 56250},\n",
       "  'KNeighborsClassifier': {'predicted': array([0, 0, 0, ..., 0, 0, 0]),\n",
       "   'accuracy': 0.9843125,\n",
       "   'confusion_matrix': array([[15585,    40],\n",
       "          [  211,   164]]),\n",
       "   'sensibility': 0.43733333333333335,\n",
       "   'specificity': 0.99744,\n",
       "   'score': 105900},\n",
       "  'RandomForestClassifier': {'predicted': array([0, 0, 0, ..., 0, 0, 0]),\n",
       "   'accuracy': 0.99175,\n",
       "   'confusion_matrix': array([[15605,    20],\n",
       "          [  112,   263]]),\n",
       "   'sensibility': 0.7013333333333334,\n",
       "   'specificity': 0.99872,\n",
       "   'score': 56200}},\n",
       " 'Mean': {'BernoulliNB': {'predicted': array([0, 0, 0, ..., 0, 0, 0]),\n",
       "   'accuracy': 0.9289375,\n",
       "   'confusion_matrix': array([[14562,  1063],\n",
       "          [   74,   301]]),\n",
       "   'sensibility': 0.8026666666666666,\n",
       "   'specificity': 0.931968,\n",
       "   'score': 47630},\n",
       "  'DecisionTreeClassifier': {'predicted': array([0, 0, 0, ..., 0, 0, 0]),\n",
       "   'accuracy': 0.98875,\n",
       "   'confusion_matrix': array([[15553,    72],\n",
       "          [  108,   267]]),\n",
       "   'sensibility': 0.712,\n",
       "   'specificity': 0.995392,\n",
       "   'score': 54720},\n",
       "  'KNeighborsClassifier': {'predicted': array([0, 0, 0, ..., 0, 0, 0]),\n",
       "   'accuracy': 0.9845,\n",
       "   'confusion_matrix': array([[15582,    43],\n",
       "          [  205,   170]]),\n",
       "   'sensibility': 0.4533333333333333,\n",
       "   'specificity': 0.997248,\n",
       "   'score': 102930},\n",
       "  'RandomForestClassifier': {'predicted': array([0, 0, 0, ..., 0, 0, 0]),\n",
       "   'accuracy': 0.992875,\n",
       "   'confusion_matrix': array([[15611,    14],\n",
       "          [  100,   275]]),\n",
       "   'sensibility': 0.7333333333333333,\n",
       "   'specificity': 0.999104,\n",
       "   'score': 50140}},\n",
       " 'Median': {'BernoulliNB': {'predicted': array([0, 0, 1, ..., 0, 0, 0]),\n",
       "   'accuracy': 0.925875,\n",
       "   'confusion_matrix': array([[14497,  1128],\n",
       "          [   58,   317]]),\n",
       "   'sensibility': 0.8453333333333334,\n",
       "   'specificity': 0.927808,\n",
       "   'score': 40280},\n",
       "  'DecisionTreeClassifier': {'predicted': array([0, 0, 0, ..., 0, 0, 0]),\n",
       "   'accuracy': 0.9889375,\n",
       "   'confusion_matrix': array([[15553,    72],\n",
       "          [  105,   270]]),\n",
       "   'sensibility': 0.72,\n",
       "   'specificity': 0.995392,\n",
       "   'score': 53220},\n",
       "  'KNeighborsClassifier': {'predicted': array([0, 0, 0, ..., 0, 0, 0]),\n",
       "   'accuracy': 0.9845625,\n",
       "   'confusion_matrix': array([[15585,    40],\n",
       "          [  207,   168]]),\n",
       "   'sensibility': 0.448,\n",
       "   'specificity': 0.99744,\n",
       "   'score': 103900},\n",
       "  'RandomForestClassifier': {'predicted': array([0, 0, 0, ..., 0, 0, 0]),\n",
       "   'accuracy': 0.992375,\n",
       "   'confusion_matrix': array([[15608,    17],\n",
       "          [  105,   270]]),\n",
       "   'sensibility': 0.72,\n",
       "   'specificity': 0.998912,\n",
       "   'score': 52670}},\n",
       " 'Most Frequent': {'BernoulliNB': {'predicted': array([0, 0, 0, ..., 0, 0, 0]),\n",
       "   'accuracy': 0.9173125,\n",
       "   'confusion_matrix': array([[14351,  1274],\n",
       "          [   49,   326]]),\n",
       "   'sensibility': 0.8693333333333333,\n",
       "   'specificity': 0.918464,\n",
       "   'score': 37240},\n",
       "  'DecisionTreeClassifier': {'predicted': array([0, 0, 0, ..., 0, 0, 0]),\n",
       "   'accuracy': 0.988375,\n",
       "   'confusion_matrix': array([[15546,    79],\n",
       "          [  107,   268]]),\n",
       "   'sensibility': 0.7146666666666667,\n",
       "   'specificity': 0.994944,\n",
       "   'score': 54290},\n",
       "  'KNeighborsClassifier': {'predicted': array([0, 0, 0, ..., 0, 0, 0]),\n",
       "   'accuracy': 0.9843125,\n",
       "   'confusion_matrix': array([[15585,    40],\n",
       "          [  211,   164]]),\n",
       "   'sensibility': 0.43733333333333335,\n",
       "   'specificity': 0.99744,\n",
       "   'score': 105900},\n",
       "  'RandomForestClassifier': {'predicted': array([0, 0, 0, ..., 0, 0, 0]),\n",
       "   'accuracy': 0.99225,\n",
       "   'confusion_matrix': array([[15611,    14],\n",
       "          [  110,   265]]),\n",
       "   'sensibility': 0.7066666666666667,\n",
       "   'specificity': 0.999104,\n",
       "   'score': 55140}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_zero, X_test_zero = X_train.fillna(0), X_test.fillna(0)\n",
    "X_train_mean, X_test_mean = X_train.fillna(X_train.mean()), X_test.fillna(X_train.mean())\n",
    "X_train_median, X_test_median = X_train.fillna(X_train.median()), X_test.fillna(X_train.median())\n",
    "X_train_mfrequent, X_test_mfrequent = X_train, X_test\n",
    "for col in X_train:\n",
    "    mode = X_train[col].dropna().mode()[0]\n",
    "    X_train_mfrequent[col] = X_train_mfrequent[col].fillna(mode) \n",
    "    X_test_mfrequent[col] = X_test_mfrequent[col].fillna(mode) \n",
    "\n",
    "X_data = {'Zero replace': (X_train_zero, X_test_zero), 'Mean': (X_train_mean, X_test_mean), 'Median': (X_train_median, X_test_median), 'Most Frequent': (X_train_mfrequent, X_test_mfrequent)}\n",
    "#plot_comparison_results(base_clfs, X_data, y_train, y_test, technique='Technique', filename='missing_values', figsize=(20, 6))\n",
    "#plot_results_from_csv('missing_values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(X_train, X_test):\n",
    "    normalizer = Normalizer().fit(X_train)\n",
    "\n",
    "    X_train_norm = normalizer.transform(X_train)\n",
    "    X_test_norm = normalizer.transform(X_test)\n",
    "    \n",
    "    return X_train_norm, X_test_norm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "neighbors = np.arange(3,20,2)\n",
    "knns = []\n",
    "\n",
    "for n_neigh in neighbors:\n",
    "    knns.append(KNeighborsClassifier(n_neighbors=n_neigh))\n",
    "    \n",
    "X_data = {\n",
    "    'Mean replace': (X_train_mean, X_test_mean),\\\n",
    "    'Normalized': (X_train_knn_norm, X_test_knn_norm),\\\n",
    "    'Balanced': (X_train_knn_smote, X_test_knn),\\\n",
    "}\n",
    "y_data = {\n",
    "    'Mean replace': y_train,\\\n",
    "    'Normalized': y_train,\\\n",
    "    'Balanced': y_train_knn,\\\n",
    "}\n",
    "    \n",
    "#plot_param_improv(knns, X_data, y_data, y_test, neighbors, param='k', filename='knn', style='darkgrid', figsize=(12,6))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
