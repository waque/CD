{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing supertable with KBest, balanced and CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import mutual_info_classif, f_classif, SelectKBest\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import Normalizer, StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS = 'consensus'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_dataset(dataset, classe):\n",
    "    y = dataset[classe]\n",
    "    X = dataset.drop(columns=[classe])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "    sm = SMOTE(random_state=2)\n",
    "\n",
    "    X_train_res, y_train_res = sm.fit_sample(X_train, y_train.ravel())\n",
    "    \n",
    "    \n",
    "\n",
    "    return X_train, X_test, y_train, y_test, X_train_res, y_train_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getKBest(X, y, score_func=f_classif, k=10):\n",
    "    k_best = SelectKBest(score_func=score_func, k=10).fit(X, y)\n",
    "\n",
    "    idxs = k_best.get_support(indices=True)\n",
    "    X = X.iloc[:,idxs]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset, y_name, missing_values=None):\n",
    "    if missing_values:\n",
    "        for value in missing_values:\n",
    "            dataset = dataset[~dataset.eq(value).any(1)]\n",
    "    \n",
    "    X = dataset.iloc[:, dataset.columns != y_name]\n",
    "    y = dataset[y_name]\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_statistics(clf, X_train, X_test, y_train, y_test):\n",
    "    res = {}\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    predicted = clf.predict(X_test)\n",
    "    conf_matrix = confusion_matrix(y_test, predicted, labels=[0.0, 1.0])\n",
    "    acc_score = accuracy_score(y_test, predicted)\n",
    "    \n",
    "    res['predicted'] = predicted\n",
    "    res['accuracy'] = acc_score\n",
    "    res['confusion_matrix'] = conf_matrix\n",
    "    fpr, tpr, _ = roc_curve(y_test, predicted)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    res['auc'] = roc_auc\n",
    "    \n",
    "    res['clf'] = clf\n",
    "    \n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(X_train, X_test):\n",
    "    normalizer = Normalizer().fit(X_train)\n",
    "\n",
    "    X_train_norm = normalizer.transform(X_train)\n",
    "    X_test_norm = normalizer.transform(X_test)\n",
    "    \n",
    "    return X_train_norm, X_test_norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = BernoulliNB()\n",
    "clf2 = DecisionTreeClassifier()\n",
    "clf3 = KNeighborsClassifier()\n",
    "clf4 = RandomForestClassifier(n_estimators=10)\n",
    "\n",
    "base_clfs = [BernoulliNB(), DecisionTreeClassifier(), KNeighborsClassifier(), RandomForestClassifier(n_estimators=10)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "green_data = pd.read_csv('../green.csv')\n",
    "hinselmann_data = pd.read_csv('../hinselmann.csv')\n",
    "schiller_data = pd.read_csv('../schiller.csv')\n",
    "\n",
    "data = [[green_data,'green_data'], [hinselmann_data,'hinselmann_data'], [schiller_data,'schiller_data']]\n",
    "\n",
    "green_data['hinselmann']=0\n",
    "green_data['schiller']=0\n",
    "hinselmann_data['hinselmann']=1\n",
    "hinselmann_data['schiller']=0\n",
    "schiller_data['hinselmann']=0\n",
    "schiller_data['schiller']=1\n",
    "\n",
    "super_table = green_data.append(hinselmann_data)\n",
    "super_table = super_table.append(schiller_data)\n",
    "\n",
    "X, y = split_dataset(super_table, CLASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"results = {}\\nscoring = ['accuracy', 'roc_auc']\\nfor clf in base_clfs:\\n    clf_name = type(clf).__name__\\n    stats = cross_validate(clf, X, y, scoring=scoring, cv=10, return_train_score=False)\\n    results[clf_name] = {}\\n    results[clf_name]['accuracy'] = np.mean(stats['test_accuracy'])\\n    results[clf_name]['roc'] = np.mean(stats['test_roc_auc'])\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"results = {}\n",
    "scoring = ['accuracy', 'roc_auc']\n",
    "for clf in base_clfs:\n",
    "    clf_name = type(clf).__name__\n",
    "    stats = cross_validate(clf, X, y, scoring=scoring, cv=10, return_train_score=False)\n",
    "    results[clf_name] = {}\n",
    "    results[clf_name]['accuracy'] = np.mean(stats['test_accuracy'])\n",
    "    results[clf_name]['roc'] = np.mean(stats['test_roc_auc'])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's test unbalanced super dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_unbal = {}\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "for clf in base_clfs:\n",
    "    clf_name = type(clf).__name__\n",
    "    stats = classifier_statistics(clf, X_train, X_test, y_train, y_test)\n",
    "    results_unbal[clf_name] = stats\n",
    "\n",
    "measures_unbal = {}\n",
    "i = 0\n",
    "for clf in results_unbal:\n",
    "    clf_res = results_unbal[clf]\n",
    "    measures_unbal[i] = {'Classifier': clf, 'Measure': 'auc', 'Value': clf_res['auc']}\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'Classifier': 'BernoulliNB',\n",
       "  'Measure': 'auc',\n",
       "  'Value': 0.780264817150063},\n",
       " 1: {'Classifier': 'DecisionTreeClassifier',\n",
       "  'Measure': 'auc',\n",
       "  'Value': 0.8215636822194199},\n",
       " 2: {'Classifier': 'KNeighborsClassifier',\n",
       "  'Measure': 'auc',\n",
       "  'Value': 0.6018284993694829},\n",
       " 3: {'Classifier': 'RandomForestClassifier',\n",
       "  'Measure': 'auc',\n",
       "  'Value': 0.8792559899117276}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measures_unbal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now let's explore balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_super, X_test_super, y_train_super, y_test_super, X_train_res_super, y_train_res_super = balance_dataset(super_table, 'consensus')\n",
    "results_bal = {}\n",
    "\n",
    "for clf in base_clfs:\n",
    "    clf_name = type(clf).__name__\n",
    "    stats = classifier_statistics(clf, X_train_res_super, X_test_super, y_train_res_super, y_test_super)\n",
    "    results_bal[clf_name] = stats\n",
    "\n",
    "measures_bal = {}\n",
    "i = 0\n",
    "for clf in results_bal:\n",
    "    clf_res = results_bal[clf]\n",
    "    measures_bal[i] = {'Classifier': clf, 'Measure': 'auc', 'Value': clf_res['auc']}\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'Classifier': 'BernoulliNB',\n",
       "  'Measure': 'auc',\n",
       "  'Value': 0.917717528373266},\n",
       " 1: {'Classifier': 'DecisionTreeClassifier',\n",
       "  'Measure': 'auc',\n",
       "  'Value': 0.8215636822194199},\n",
       " 2: {'Classifier': 'KNeighborsClassifier',\n",
       "  'Measure': 'auc',\n",
       "  'Value': 0.599936948297604},\n",
       " 3: {'Classifier': 'RandomForestClassifier',\n",
       "  'Measure': 'auc',\n",
       "  'Value': 0.8325977301387137}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measures_bal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explorar 3 datasets juntos + SMOTE + normalização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_super, X_test_super, y_train_super, y_test_super, X_train_res_super, y_train_res_super = balance_dataset(super_table, 'consensus')\n",
    "X_train_norm, X_test_norm = normalize(X_train_res_super, X_test_super)\n",
    "\n",
    "results_nor = {}\n",
    "\n",
    "for clf in base_clfs:\n",
    "    clf_name = type(clf).__name__\n",
    "    stats = classifier_statistics(clf, X_train_norm, X_test_norm, y_train_res_super, y_test_super)\n",
    "    results_nor[clf_name] = stats\n",
    "\n",
    "measures_nor = {}\n",
    "i = 0\n",
    "for clf in results_nor:\n",
    "    clf_res = results_nor[clf]\n",
    "    measures_nor[i] = {'Classifier': clf, 'Measure': 'auc', 'Value': clf_res['auc']}\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'Classifier': 'BernoulliNB',\n",
       "  'Measure': 'auc',\n",
       "  'Value': 0.917717528373266},\n",
       " 1: {'Classifier': 'DecisionTreeClassifier',\n",
       "  'Measure': 'auc',\n",
       "  'Value': 0.7503152585119799},\n",
       " 2: {'Classifier': 'KNeighborsClassifier',\n",
       "  'Measure': 'auc',\n",
       "  'Value': 0.6273644388398487},\n",
       " 3: {'Classifier': 'RandomForestClassifier',\n",
       "  'Measure': 'auc',\n",
       "  'Value': 0.8080075662042876}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measures_nor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = BernoulliNB()\n",
    "clf2 = DecisionTreeClassifier()\n",
    "clf3 = KNeighborsClassifier()\n",
    "clf4 = RandomForestClassifier(n_estimators=10)\n",
    "eclf1 = VotingClassifier(estimators=[('nb', clf1), ('bt', clf2), ('knn', clf3), ('rf', clf4)], voting='hard')\n",
    "\n",
    "base_clfs = [BernoulliNB(), DecisionTreeClassifier(), KNeighborsClassifier(), RandomForestClassifier(n_estimators=10), eclf1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = getKBest(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "sm = SMOTE(random_state=2)\n",
    "\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train.ravel())\n",
    "\n",
    "results_kbest = {}\n",
    "\n",
    "for clf in base_clfs:\n",
    "    clf_name = type(clf).__name__\n",
    "    stats = classifier_statistics(clf, X_train_res, X_test, y_train_res, y_test)\n",
    "    results_kbest[clf_name] = stats\n",
    "\n",
    "measures_kbest = {}\n",
    "i = 0\n",
    "for clf in results_kbest:\n",
    "    clf_res = results_kbest[clf]\n",
    "    measures_kbest[i] = {'Classifier': clf, 'Measure': 'auc', 'Value': clf_res['auc']}\n",
    "    i += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'Classifier': 'BernoulliNB',\n",
       "  'Measure': 'auc',\n",
       "  'Value': 0.9508196721311475},\n",
       " 1: {'Classifier': 'DecisionTreeClassifier',\n",
       "  'Measure': 'auc',\n",
       "  'Value': 0.8407944514501892},\n",
       " 2: {'Classifier': 'KNeighborsClassifier',\n",
       "  'Measure': 'auc',\n",
       "  'Value': 0.6793820933165196},\n",
       " 3: {'Classifier': 'RandomForestClassifier',\n",
       "  'Measure': 'auc',\n",
       "  'Value': 0.9451450189155108},\n",
       " 4: {'Classifier': 'VotingClassifier',\n",
       "  'Measure': 'auc',\n",
       "  'Value': 0.882093316519546}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measures_kbest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_overfit = {}\n",
    "i = 0\n",
    "n_estimators = 10\n",
    "min_samples_split = 2\n",
    "while min_samples_split < 100:\n",
    "    clf = RandomForestClassifier(n_estimators=n_estimators, min_samples_split = min_samples_split, random_state=2)\n",
    "    stats_train = classifier_statistics(clf, X_train_res, X_train_res, y_train_res, y_train_res)\n",
    "    stats_test = classifier_statistics(clf, X_train_res, X_test, y_train_res, y_test)\n",
    "    results_overfit[min_samples_split] = {'train': stats_train['auc'], 'test': stats_test['auc']}\n",
    "    i += 1\n",
    "    #n_estimators += 1\n",
    "    min_samples_split += 2\n",
    "results_overfit = pd.DataFrame.from_dict(results_overfit, \"index\")\n",
    "results_overfit.to_csv('../plot_data/{}.csv'.format('overfiting_test_9'))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_overfit_knn = {}\n",
    "n = 3\n",
    "while n <= 100:\n",
    "    clf = KNeighborsClassifier(n_neighbors=n)\n",
    "    stats_train = classifier_statistics(clf, X_train_res, X_train_res, y_train_res, y_train_res)\n",
    "    stats_test = classifier_statistics(clf, X_train_res, X_test, y_train_res, y_test)\n",
    "    results_overfit_knn[n] = {'train': stats_train['auc'], 'test': stats_test['auc']}\n",
    "    n+=2\n",
    "results_overfit = pd.DataFrame.from_dict(results_overfit_knn, \"index\")\n",
    "results_overfit.to_csv('../plot_data/{}.csv'.format('overfiting_test_8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_RF = dict(n_estimators=list(range(3, 40)), max_depth=list(range(4, 30)), min_samples_split=list(range(10, 100)))\n",
    "clf_RF = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rand_RF = RandomizedSearchCV(clf_RF, param_RF, cv=10, scoring='roc_auc', \n",
    "                             n_iter=10, random_state=5, return_train_score=False)\n",
    "\n",
    "rand_RF.fit(X_train_res, y_train_res)\n",
    "r = pd.DataFrame(rand_RF.cv_results_)[['mean_test_score', 'std_test_score', 'params']]\n",
    "r.to_csv('../plot_data/{}.csv'.format('RandomizedSearchCV'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_depth = {}\n",
    "i = 0\n",
    "min_samples_split = 2\n",
    "max_depth = 1\n",
    "while min_samples_split < 70:\n",
    "    clf = DecisionTreeClassifier(min_samples_split=min_samples_split, max_depth=max_depth, random_state=2)\n",
    "    stats_train = classifier_statistics(clf, X_train_res, X_train_res, y_train_res, y_train_res)\n",
    "    stats_test = classifier_statistics(clf, X_train_res, X_test, y_train_res, y_test)\n",
    "    results_depth[stats_train['clf'].tree_.node_count] = {'train': stats_train['auc'], 'test': stats_test['auc'] }\n",
    "    min_samples_split += 1\n",
    "    if max_depth and max_depth < 3:\n",
    "        max_depth += 1\n",
    "    else:\n",
    "        max_depth = None\n",
    "results_overfit = pd.DataFrame.from_dict(results_depth, \"index\")\n",
    "results_overfit.to_csv('../plot_data/{}.csv'.format('tree_size'))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
